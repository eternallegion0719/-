{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "479d4786-418f-407e-ae7e-7ae9cc347703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "합계 1.6M\n",
      "-rw-rw-r-- 1 eternal eternal  301K 11월 24 22:13 sts-dev.tsv\n",
      "-rw-rw-r-- 1 eternal eternal  244K 11월 24 22:13 sts-test.tsv\n",
      "-rw-rw-r-- 1 eternal eternal 1023K 11월 24 22:13 sts-train.tsv\n"
     ]
    }
   ],
   "source": [
    "dr='/home/eternal/Korpora/korsts/'\n",
    "!ls -lh $dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41e563b2-b0e0-445c-b274-f4b7a8cd0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "ps.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d23979f-b2b1-4583-abcd-355cc0382437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10564/4240241422.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train = ps.read_csv(dr + 'sts-train.tsv', sep='/t')\n",
      "/tmp/ipykernel_10564/4240241422.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test = ps.read_csv(dr + 'sts-test.tsv', sep='/t')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre\\tfilename\\tyear\\tid\\tscore\\tsentence1\\tsentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-captions\\tMSRvid\\t2012test\\t0024\\t2.500\\t한 소녀가 머리를 스타일링하고 있다.\\t한 소녀가 머리를 빗고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-captions\\tMSRvid\\t2012test\\t0033\\t3.600\\t한 무리의 남자들이 해변에서 축구를 한다.\\t한 무리의 소년들이 해변에서 축구를 하고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-captions\\tMSRvid\\t2012test\\t0045\\t5.000\\t한 여성이 다른 여성의 발목을 재고 있다.\\t한 여자는 다른 여자의 발목을 측정한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-captions\\tMSRvid\\t2012test\\t0063\\t4.200\\t한 남자가 오이를 자르고 있다.\\t한 남자가 오이를 자르고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-captions\\tMSRvid\\t2012test\\t0066\\t1.500\\t한 남자가 하프를 연주하고 있다.\\t한 남자가 키보드를 연주하고 있다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genre\\tfilename\\tyear\\tid\\tscore\\tsentence1\\tsentence2\n",
       "0               main-captions\\tMSRvid\\t2012test\\t0024\\t2.500\\t한 소녀가 머리를 스타일링하고 있다.\\t한 소녀가 머리를 빗고 있다.\n",
       "1  main-captions\\tMSRvid\\t2012test\\t0033\\t3.600\\t한 무리의 남자들이 해변에서 축구를 한다.\\t한 무리의 소년들이 해변에서 축구를 하고 있다.\n",
       "2      main-captions\\tMSRvid\\t2012test\\t0045\\t5.000\\t한 여성이 다른 여성의 발목을 재고 있다.\\t한 여자는 다른 여자의 발목을 측정한다.\n",
       "3                 main-captions\\tMSRvid\\t2012test\\t0063\\t4.200\\t한 남자가 오이를 자르고 있다.\\t한 남자가 오이를 자르고 있다.\n",
       "4              main-captions\\tMSRvid\\t2012test\\t0066\\t1.500\\t한 남자가 하프를 연주하고 있다.\\t한 남자가 키보드를 연주하고 있다."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ps.read_csv(dr + 'sts-train.tsv', sep='/t')\n",
    "#a=ps.read_csv('/home/eternal/Korpora/korsts/sts-train.tsv',delimiter='\\t')\n",
    "train.head()\n",
    "\n",
    "test = ps.read_csv(dr + 'sts-test.tsv', sep='/t')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ac4c8ba-f135-4e1f-94e5-9f9e012790f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "425c5253-f31e-4094-abd8-5f748991b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "predefined_args = {\n",
    "        'attention_cell': 'multi_head',\n",
    "        'num_layers': 12,\n",
    "        'units': 768,\n",
    "        'hidden_size': 3072,\n",
    "        'max_length': 512,\n",
    "        'num_heads': 12,\n",
    "        'scaled': True,\n",
    "        'dropout': 0.1,\n",
    "        'use_residual': True,\n",
    "        'embed_size': 768,\n",
    "        'embed_dropout': 0.1,\n",
    "        'token_type_vocab_size': 2,\n",
    "        'word_embed': None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "420315a7-eb19-4a7a-a3f9-f6d1d13701f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KoBERT\n",
      "Korpora\n",
      "Untitled.ipynb\n",
      "Untitled1.ipynb\n",
      "Untitled2.ipynb\n",
      "Untitled3.ipynb\n",
      "Untitled4.ipynb\n",
      "Untitled5.ipynb\n",
      "apex\n",
      "bart-base\n",
      "beomi\n",
      "bert\n",
      "bert-base-uncased-vocab.txt\n",
      "bert-base-uncased-vocab.txt.1\n",
      "checkpoint-qa\n",
      "clients\n",
      "cuda-repo-ubuntu2204-12-3-local_12.3.1-545.23.08-1_amd64.deb\n",
      "cuda-repo-ubuntu2204-12-3-local_12.3.1-545.23.08-1_amd64.deb.1\n",
      "cuda-ubuntu2004.pin\n",
      "data\n",
      "dev-v1.1.json\n",
      "get-docker.sh\n",
      "google-chrome-stable_current_amd64.deb\n",
      "inputs\n",
      "korquad.github.io\n",
      "korquad.json\n",
      "korquad_data\n",
      "multi_cased_L-12_H-768_A-12\n",
      "multi_cased_L-12_H-768_A-12.zip\n",
      "my-project\n",
      "nsmc\n",
      "server\n",
      "setuptools\n",
      "snap\n",
      "test.ipynb\n",
      "tokenizers\n",
      "train-v1.1.json\n",
      "transformers\n",
      "venv\n",
      "vocabulary.txt\n",
      "wikitext-103-raw\n",
      "wikitext-103-raw-v1.zip\n",
      "wikitext-103-raw-v1.zip.1\n",
      "works\n",
      "공개\n",
      "다운로드\n",
      "문서\n",
      "바탕화면\n",
      "비디오\n",
      "사진\n",
      "음악\n",
      "템플릿\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
    "#!git clone https://github.com/SKTBrain/KoBERT.git\n",
    "!cd /home/eternal/KoBERT/\n",
    "!ls\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "672d1a9e-e49e-480f-bfd5-6afae0373335",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4168097395.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[42], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    grad_fn=<SelectBackward>)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from kobert import get_pytorch_kobert_model\n",
    "input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "model, vocab  = get_pytorch_kobert_model()\n",
    "sequence_output, pooled_output = model(input_ids, input_mask, token_type_ids)\n",
    "pooled_output.shape\n",
    "torch.Size([2, 768])\n",
    "vocab\n",
    "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[MASK]', '[SEP]', '[CLS]']\")\n",
    "# Last Encoding Layer\n",
    "equence_output[0]\n",
    "tensor([[-0.2461,  0.2428,  0.2590,  ..., -0.4861, -0.0731,  0.0756],\n",
    "        [-0.2478,  0.2420,  0.2552,  ..., -0.4877, -0.0727,  0.0754],\n",
    "        [-0.2472,  0.2420,  0.2561,  ..., -0.4874, -0.0733,  0.0765]],\n",
    "       grad_fn=<SelectBackward>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fde75b05-f24d-469b-9b3e-03d26e72165d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kobert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkobert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_onnx_kobert_model\n\u001b[1;32m      4\u001b[0m onnx_path \u001b[38;5;241m=\u001b[39m get_onnx_kobert_model()\n\u001b[1;32m      5\u001b[0m sess \u001b[38;5;241m=\u001b[39m onnxruntime\u001b[38;5;241m.\u001b[39mInferenceSession(onnx_path)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kobert'"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "from kobert import get_onnx_kobert_model\n",
    "onnx_path = get_onnx_kobert_model()\n",
    "sess = onnxruntime.InferenceSession(onnx_path)\n",
    "input_ids = [[31, 51, 99], [15, 5, 0]]\n",
    "input_mask = [[1, 1, 1], [1, 1, 0]]\n",
    "token_type_ids = [[0, 0, 1], [0, 1, 0]]\n",
    "len_seq = len(input_ids[0])\n",
    "\n",
    "pred_onnx = sess.run(None, {'input_ids':np.array(input_ids),\n",
    "\n",
    "                             'token_type_ids':np.array(token_type_ids),\n",
    "                             'input_mask':np.array(input_mask),\n",
    "                             'position_ids':np.array(range(len_seq))})\n",
    "\n",
    "\n",
    "pred_onnx[-2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c67eb-f0cf-4c51-91f3-e23d068132bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "689470ee-f640-4743-b515-9a5f080c81b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.28.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in ./.local/lib/python3.10/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "tokenizers>=0.14,<0.19 is required for a normal functioning of this module, but found tokenizers==0.13.3.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install transformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFBertForMaskedLM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m TFBertForMaskedLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mklue/bert-base\u001b[39m\u001b[38;5;124m'\u001b[39m, from_pt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     logging,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     50\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/dependency_versions_check.py:57\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     \u001b[43mrequire_version_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeps\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, check dependency_versions_table.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/versions.py:117\u001b[0m, in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry: pip install transformers -U or pip install -e \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.[dev]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre working with git main\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequire_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/versions.py:111\u001b[0m, in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op, want_ver \u001b[38;5;129;01min\u001b[39;00m wanted\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 111\u001b[0m         \u001b[43m_compare_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgot_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwant_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/versions.py:44\u001b[0m, in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to compare versions for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: need=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwant_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is unusual. Consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reinstalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops[op](version\u001b[38;5;241m.\u001b[39mparse(got_ver), version\u001b[38;5;241m.\u001b[39mparse(want_ver)):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is required for a normal functioning of this module, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: tokenizers>=0.14,<0.19 is required for a normal functioning of this module, but found tokenizers==0.13.3.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = TFBertForMaskedLM.from_pretrained('klue/bert-base', from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2afdcad-5cb1-4eb4-8bd2-b05533da50ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m축구는 정말 재미있는 [MASK]다.\u001b[39m\u001b[38;5;124m'\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('축구는 정말 재미있는 [MASK]다.', return_tensors='tf')\n",
    "print(inputs['input_ids'])\n",
    "print(inputs['token_type_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59f8a870-3e45-4ead-aee2-f69847d052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', } \n",
    "\n",
    "\n",
    "def clean(text, punct, mapping):\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_str(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '<[^>]*>'         # HTML 태그 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '[^\\w\\s\\n]'         # 특수기호제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', string=text)\n",
    "    text = re.sub('\\n', '.', string=text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad205cff-ca19-4f9b-9a36-7058de9ac291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172be92-2c9a-4c9b-ab56-56fde4b2934c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437972b1-0587-42a2-bd04-a5ecfefb6750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf61c5-c9e9-4c03-8cb1-b396fe1c22c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc4eb5e-c684-436c-9414-0fe78da7778f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343798b-f49e-413a-aeed-beeff1f4c28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff040b-d6da-4d23-bfa1-1d513e77819a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6e7cc-9c59-4e83-8fd9-61f46d011192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa05bb-41f1-4cd6-8ef8-c1ff264d7a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d50322-1e1d-4433-b182-d5f13b54f183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2913be2-a251-4251-97c8-f2ee08dc659a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efd32478-3c6f-48a2-b310-b8d1a60876f4",
   "metadata": {},
   "source": [
    "'여기서부터 진짜'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fb5dc003-0c9b-4fef-bf2e-5057397bc102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kcbert': 'beomi@github 님이 만드신 KcBERT 학습데이터',\n",
       " 'korean_chatbot_data': 'songys@github 님이 만드신 챗봇 문답 데이터',\n",
       " 'korean_hate_speech': '{inmoonlight,warnikchow,beomi}@github 님이 만드신 혐오댓글데이터',\n",
       " 'korean_parallel_koen_news': 'jungyeul@github 님이 만드신 병렬 말뭉치',\n",
       " 'korean_petitions': 'lovit@github 님이 만드신 2017.08 ~ 2019.03 청와대 청원데이터',\n",
       " 'kornli': 'KakaoBrain 에서 제공하는 Natural Language Inference (NLI) 데이터',\n",
       " 'korsts': 'KakaoBrain 에서 제공하는 Semantic Textual Similarity (STS) 데이터',\n",
       " 'kowikitext': 'lovit@github 님이 만드신 wikitext 형식의 한국어 위키피디아 데이터',\n",
       " 'namuwikitext': 'lovit@github 님이 만드신 wikitext 형식의 나무위키 데이터',\n",
       " 'naver_changwon_ner': '네이버 + 창원대 NER shared task data',\n",
       " 'nsmc': 'e9t@github 님이 만드신 Naver sentiment movie corpus v1.0',\n",
       " 'question_pair': 'songys@github 님이 만드신 질문쌍(Paired Question v.2)',\n",
       " 'modu_news': '국립국어원에서 만든 모두의 말뭉치: 뉴스 말뭉치',\n",
       " 'modu_messenger': '국립국어원에서 만든 모두의 말뭉치: 메신저 말뭉치',\n",
       " 'modu_mp': '국립국어원에서 만든 모두의 말뭉치: 형태 분석 말뭉치',\n",
       " 'modu_ne': '국립국어원에서 만든 모두의 말뭉치: 개체명 분석 말뭉치',\n",
       " 'modu_spoken': '국립국어원에서 만든 모두의 말뭉치: 구어 말뭉치',\n",
       " 'modu_web': '국립국어원에서 만든 모두의 말뭉치: 웹 말뭉치',\n",
       " 'modu_written': '국립국어원에서 만든 모두의 말뭉치: 문어 말뭉치',\n",
       " 'open_subtitles': 'Open parallel corpus (OPUS) 에서 제공하는 영화 자막 번역 병렬 말뭉치',\n",
       " 'aihub_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어 + 대화 + 뉴스 + 한국문화 + 조례 + 지자체웹사이트)',\n",
       " 'aihub_spoken_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어)',\n",
       " 'aihub_conversation_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (대화)',\n",
       " 'aihub_news_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (뉴스)',\n",
       " 'aihub_korean_culture_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (한국문화)',\n",
       " 'aihub_decree_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (조례)',\n",
       " 'aihub_government_website_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (지자체웹사이트)'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "Korpora.corpus_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8799b54f-93c7-49bc-8ce1-9454384f57f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzaa\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzab\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzac\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "Korpora.fetch(\"kcbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "923c3a50-fd8f-4af4-be6c-79da298283c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : beomi@github\n",
      "    Repository : https://github.com/Beomi/KcBERT/\n",
      "    References :\n",
      "\n",
      "    공개된 한국어 BERT는 대부분 한국어 위키, 뉴스 기사, 책 등 잘 정제된 데이터를 기반으로 학습한 모델입니다.\n",
      "\n",
      "    한편, 실제로 NSMC와 같은 댓글형 데이터셋은 정제되지 않았고 구어체 특징에 신조어가 많으며,\n",
      "    오탈자 등 공식적인 글쓰기에서 나타나지 않는 표현들이 빈번하게 등장합니다.\n",
      "\n",
      "    KcBERT는 위와 같은 특성의 데이터셋에 적용하기 위해, 네이버 뉴스에서 댓글과 대댓글을 수집해,\n",
      "    토크나이저와 BERT모델을 처음부터 학습한 Pretrained BERT 모델입니다.\n",
      "\n",
      "    KcBERT는 Huggingface의 Transformers 라이브러리를 통해 간편히 불러와 사용할 수 있습니다.\n",
      "    (별도의 파일 다운로드가 필요하지 않습니다.)\n",
      "\n",
      "    # License\n",
      "    MIT License\n",
      "\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzaa\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzab\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "KcBERT text file is large (12G).\n",
      "If you want to load text in your memory, please insert `yes`\n",
      "If the `INPUT` is integer, it loads only first `INPUT` sentences\n",
      " INPIUT\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "corpus = Korpora.load(\"kcbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d5c60fb5-174a-4575-9506-ae013bc8452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : beomi@github\n",
      "    Repository : https://github.com/Beomi/KcBERT/\n",
      "    References :\n",
      "\n",
      "    공개된 한국어 BERT는 대부분 한국어 위키, 뉴스 기사, 책 등 잘 정제된 데이터를 기반으로 학습한 모델입니다.\n",
      "\n",
      "    한편, 실제로 NSMC와 같은 댓글형 데이터셋은 정제되지 않았고 구어체 특징에 신조어가 많으며,\n",
      "    오탈자 등 공식적인 글쓰기에서 나타나지 않는 표현들이 빈번하게 등장합니다.\n",
      "\n",
      "    KcBERT는 위와 같은 특성의 데이터셋에 적용하기 위해, 네이버 뉴스에서 댓글과 대댓글을 수집해,\n",
      "    토크나이저와 BERT모델을 처음부터 학습한 Pretrained BERT 모델입니다.\n",
      "\n",
      "    KcBERT는 Huggingface의 Transformers 라이브러리를 통해 간편히 불러와 사용할 수 있습니다.\n",
      "    (별도의 파일 다운로드가 필요하지 않습니다.)\n",
      "\n",
      "    # License\n",
      "    MIT License\n",
      "\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzaa\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzab\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "KcBERT text file is large (12G).\n",
      "If you want to load text in your memory, please insert `yes`\n",
      "If the `INPUT` is integer, it loads only first `INPUT` sentences\n",
      " INPUT\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "corpus = Korpora.load(\"kcbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4593a70d-8700-49c2-b99d-b76a514478c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kcbert': 'beomi@github 님이 만드신 KcBERT 학습데이터',\n",
       " 'korean_chatbot_data': 'songys@github 님이 만드신 챗봇 문답 데이터',\n",
       " 'korean_hate_speech': '{inmoonlight,warnikchow,beomi}@github 님이 만드신 혐오댓글데이터',\n",
       " 'korean_parallel_koen_news': 'jungyeul@github 님이 만드신 병렬 말뭉치',\n",
       " 'korean_petitions': 'lovit@github 님이 만드신 2017.08 ~ 2019.03 청와대 청원데이터',\n",
       " 'kornli': 'KakaoBrain 에서 제공하는 Natural Language Inference (NLI) 데이터',\n",
       " 'korsts': 'KakaoBrain 에서 제공하는 Semantic Textual Similarity (STS) 데이터',\n",
       " 'kowikitext': 'lovit@github 님이 만드신 wikitext 형식의 한국어 위키피디아 데이터',\n",
       " 'namuwikitext': 'lovit@github 님이 만드신 wikitext 형식의 나무위키 데이터',\n",
       " 'naver_changwon_ner': '네이버 + 창원대 NER shared task data',\n",
       " 'nsmc': 'e9t@github 님이 만드신 Naver sentiment movie corpus v1.0',\n",
       " 'question_pair': 'songys@github 님이 만드신 질문쌍(Paired Question v.2)',\n",
       " 'modu_news': '국립국어원에서 만든 모두의 말뭉치: 뉴스 말뭉치',\n",
       " 'modu_messenger': '국립국어원에서 만든 모두의 말뭉치: 메신저 말뭉치',\n",
       " 'modu_mp': '국립국어원에서 만든 모두의 말뭉치: 형태 분석 말뭉치',\n",
       " 'modu_ne': '국립국어원에서 만든 모두의 말뭉치: 개체명 분석 말뭉치',\n",
       " 'modu_spoken': '국립국어원에서 만든 모두의 말뭉치: 구어 말뭉치',\n",
       " 'modu_web': '국립국어원에서 만든 모두의 말뭉치: 웹 말뭉치',\n",
       " 'modu_written': '국립국어원에서 만든 모두의 말뭉치: 문어 말뭉치',\n",
       " 'open_subtitles': 'Open parallel corpus (OPUS) 에서 제공하는 영화 자막 번역 병렬 말뭉치',\n",
       " 'aihub_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어 + 대화 + 뉴스 + 한국문화 + 조례 + 지자체웹사이트)',\n",
       " 'aihub_spoken_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어)',\n",
       " 'aihub_conversation_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (대화)',\n",
       " 'aihub_news_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (뉴스)',\n",
       " 'aihub_korean_culture_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (한국문화)',\n",
       " 'aihub_decree_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (조례)',\n",
       " 'aihub_government_website_translation': 'AI Hub 에서 제공하는 번역용 병렬 말뭉치 (지자체웹사이트)'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "Korpora.corpus_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "746dd27a-286d-4002-9a87-21db3c07f072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzaa\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzab\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzac\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "Korpora.fetch(\"kcbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "621c476d-994a-43e8-8e00-d82d40fb20e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : beomi@github\n",
      "    Repository : https://github.com/Beomi/KcBERT/\n",
      "    References :\n",
      "\n",
      "    공개된 한국어 BERT는 대부분 한국어 위키, 뉴스 기사, 책 등 잘 정제된 데이터를 기반으로 학습한 모델입니다.\n",
      "\n",
      "    한편, 실제로 NSMC와 같은 댓글형 데이터셋은 정제되지 않았고 구어체 특징에 신조어가 많으며,\n",
      "    오탈자 등 공식적인 글쓰기에서 나타나지 않는 표현들이 빈번하게 등장합니다.\n",
      "\n",
      "    KcBERT는 위와 같은 특성의 데이터셋에 적용하기 위해, 네이버 뉴스에서 댓글과 대댓글을 수집해,\n",
      "    토크나이저와 BERT모델을 처음부터 학습한 Pretrained BERT 모델입니다.\n",
      "\n",
      "    KcBERT는 Huggingface의 Transformers 라이브러리를 통해 간편히 불러와 사용할 수 있습니다.\n",
      "    (별도의 파일 다운로드가 필요하지 않습니다.)\n",
      "\n",
      "    # License\n",
      "    MIT License\n",
      "\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzaa\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzab\n",
      "[Korpora] Corpus `kcbert` is already installed at /home/eternal/Korpora/kcbert/kcbert-train.tar.gzac\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "KcBERT text file is large (12G).\n",
      "If you want to load text in your memory, please insert `yes`\n",
      "If the `INPUT` is integer, it loads only first `INPUT` sentences\n",
      " INPUT\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "corpus = Korpora.load(\"kcbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c79684d-113c-406f-8947-e09d589b5b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: cuda:1\n",
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/eternal/Korpora/nsmc/ratings_train.txt\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/eternal/Korpora/nsmc/ratings_test.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 한글 자연어 처리 데이터셋\n",
    "from Korpora import Korpora\n",
    "\n",
    "# 토크나이저 관련 경고 무시하기 위하여 설정\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'true'\n",
    "\n",
    "# device 지정\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'사용 디바이스: {device}')\n",
    "\n",
    "corpus = Korpora.load(\"nsmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b14e23-c5aa-443f-a7ac-66b4bb8f1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('~/Korpora/nsmc/ratings_train.txt', sep='\\t')\n",
    "test = pd.read_csv('~/Korpora/nsmc/ratings_test.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9cab21-4e3b-47a4-bc09-e22ce9f28051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129618</th>\n",
       "      <td>9333180</td>\n",
       "      <td>한번쯤 권하고픈 애니 ㅇㅇㅇ</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120016</th>\n",
       "      <td>1689597</td>\n",
       "      <td>별로 볼만한 로맨틱 코미디는 아니다 산드라 블록이 특히 아니다</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>8251637</td>\n",
       "      <td>소설판도 영화로나왔으면 좋겠다.</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120390</th>\n",
       "      <td>4054091</td>\n",
       "      <td>라면에 초코파이를 넣고 끓여먹은 뒤 원숭이에게 트림해서 감독을 맡긴 장엄한 명작.</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9828</th>\n",
       "      <td>7356485</td>\n",
       "      <td>게살줬더니 게맛살이 더 맛있다며..;;</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72421</th>\n",
       "      <td>8335645</td>\n",
       "      <td>우리나라에서는 1월1일 7시 일부메가박스에서만 상영했어요..단1회만 상영해줌 ㅜㅜ;</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53200</th>\n",
       "      <td>1934245</td>\n",
       "      <td>사채라는 위험성을 재미로 표현하면서도 잘도 엽기적인 상업극</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86761</th>\n",
       "      <td>8915283</td>\n",
       "      <td>이런거 만들지 말자. 시간이 아깝다</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15657</th>\n",
       "      <td>1157621</td>\n",
       "      <td>채널돌리다 봤는데 재미있었다</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11194</th>\n",
       "      <td>8878343</td>\n",
       "      <td>이 영화는 7점대가 정상이다</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                        document  label  length\n",
       "129618  9333180                                 한번쯤 권하고픈 애니 ㅇㅇㅇ      1      15\n",
       "120016  1689597              별로 볼만한 로맨틱 코미디는 아니다 산드라 블록이 특히 아니다      0      34\n",
       "4432    8251637                               소설판도 영화로나왔으면 좋겠다.      0      17\n",
       "120390  4054091   라면에 초코파이를 넣고 끓여먹은 뒤 원숭이에게 트림해서 감독을 맡긴 장엄한 명작.      0      45\n",
       "9828    7356485                           게살줬더니 게맛살이 더 맛있다며..;;      1      21\n",
       "...         ...                                             ...    ...     ...\n",
       "72421   8335645  우리나라에서는 1월1일 7시 일부메가박스에서만 상영했어요..단1회만 상영해줌 ㅜㅜ;      1      46\n",
       "53200   1934245                사채라는 위험성을 재미로 표현하면서도 잘도 엽기적인 상업극      0      32\n",
       "86761   8915283                             이런거 만들지 말자. 시간이 아깝다      0      19\n",
       "15657   1157621                                 채널돌리다 봤는데 재미있었다      1      15\n",
       "11194   8878343                                 이 영화는 7점대가 정상이다      0      15\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['length'] = train['document'].apply(lambda x: len(str(x)))\n",
    "test['length'] = test['document'].apply(lambda x: len(str(x)))\n",
    "train = train.loc[train['length'] > 5]\n",
    "# 전체 데이터셋 크기가 커서 1000개의 문장을 샘플링 합니다.\n",
    "train = train.sample(1000)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf0ec5b-8337-47c6-b53d-41f0c222c43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29425</th>\n",
       "      <td>3287663</td>\n",
       "      <td>일본 만화책을 보고있는 느낌. 요괴들이 유치원수준</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16341</th>\n",
       "      <td>279224</td>\n",
       "      <td>재미없다 일본문화(특히 사무라이는)아직도 이질감이 느낀다</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47755</th>\n",
       "      <td>9609663</td>\n",
       "      <td>너무 귀엽다. 몬스터 주식회사 내용을 알고보니 좀 재미없지 않을까 했는데 알고보니 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14468</th>\n",
       "      <td>2974495</td>\n",
       "      <td>월e스페이스침스도라에몽케로로돼지코아기공룡임피의모험중가장재미없었음!!!!!!최악.</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5244</th>\n",
       "      <td>2684355</td>\n",
       "      <td>이게 뭐야 싶은 분은 꼭 보세요~ 수작은 수작입니다.</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22606</th>\n",
       "      <td>10100847</td>\n",
       "      <td>보는내내진심오졌다개짱</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38047</th>\n",
       "      <td>9450841</td>\n",
       "      <td>더빙을 했으면 DVD에는 원어를 추가해야지 왜 덴마크어가 아닌 '영어 더빙'이 나오...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15348</th>\n",
       "      <td>6481627</td>\n",
       "      <td>이런 분위기 드라마 너무 좋아요 ㅠㅠ... 진짜 드라마가 너무 예뻐요!</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47523</th>\n",
       "      <td>8621793</td>\n",
       "      <td>세계 4대 성인인 공자의 삶을 재조명한 느낌!!! 강추~!</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14653</th>\n",
       "      <td>7070215</td>\n",
       "      <td>TV에서 나오길래 보다가 1시간 후에 채널돌림... 보다가 멈춘 영화 오랜만이다.</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                           document  label  \\\n",
       "29425   3287663                        일본 만화책을 보고있는 느낌. 요괴들이 유치원수준      0   \n",
       "16341    279224                    재미없다 일본문화(특히 사무라이는)아직도 이질감이 느낀다      0   \n",
       "47755   9609663  너무 귀엽다. 몬스터 주식회사 내용을 알고보니 좀 재미없지 않을까 했는데 알고보니 ...      1   \n",
       "14468   2974495       월e스페이스침스도라에몽케로로돼지코아기공룡임피의모험중가장재미없었음!!!!!!최악.      0   \n",
       "5244    2684355                      이게 뭐야 싶은 분은 꼭 보세요~ 수작은 수작입니다.      1   \n",
       "...         ...                                                ...    ...   \n",
       "22606  10100847                                        보는내내진심오졌다개짱      1   \n",
       "38047   9450841  더빙을 했으면 DVD에는 원어를 추가해야지 왜 덴마크어가 아닌 '영어 더빙'이 나오...      0   \n",
       "15348   6481627            이런 분위기 드라마 너무 좋아요 ㅠㅠ... 진짜 드라마가 너무 예뻐요!      1   \n",
       "47523   8621793                   세계 4대 성인인 공자의 삶을 재조명한 느낌!!! 강추~!      1   \n",
       "14653   7070215      TV에서 나오길래 보다가 1시간 후에 채널돌림... 보다가 멈춘 영화 오랜만이다.      0   \n",
       "\n",
       "       length  \n",
       "29425      27  \n",
       "16341      31  \n",
       "47755      67  \n",
       "14468      44  \n",
       "5244       29  \n",
       "...       ...  \n",
       "22606      11  \n",
       "38047      51  \n",
       "15348      39  \n",
       "47523      32  \n",
       "14653      45  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.loc[test['length'] > 5]\n",
    "test = test.sample(500)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6856362e-bf9e-42ea-8545-3a1b0a887c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_NAME = 'kykim/bert-kor-base'\n",
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TokenDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, dataframe, tokenizer_pretrained):\n",
    "        # sentence, label 컬럼으로 구성된 데이터프레임 전달\n",
    "        self.data = dataframe        \n",
    "        # Huggingface 토크나이저 생성\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(tokenizer_pretrained)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data.iloc[idx]['document']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        # 토큰화 처리\n",
    "        tokens = self.tokenizer(\n",
    "            sentence,                # 1개 문장 \n",
    "            return_tensors='pt',     # 텐서로 반환\n",
    "            truncation=True,         # 잘라내기 적용\n",
    "            padding='max_length',    # 패딩 적용\n",
    "            add_special_tokens=True  # 스페셜 토큰 적용\n",
    "        )\n",
    "\n",
    "        input_ids = tokens['input_ids'].squeeze(0)           # 2D -> 1D\n",
    "        attention_mask = tokens['attention_mask'].squeeze(0) # 2D -> 1D\n",
    "        token_type_ids = torch.zeros_like(attention_mask)\n",
    "\n",
    "        # input_ids, attention_mask, token_type_ids 이렇게 3가지 요소를 반환하도록 합니다.\n",
    "        # input_ids: 토큰\n",
    "        # attention_mask: 실제 단어가 존재하면 1, 패딩이면 0 (패딩은 0이 아닐 수 있습니다)\n",
    "        # token_type_ids: 문장을 구분하는 id. 단일 문장인 경우에는 전부 0\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask, \n",
    "            'token_type_ids': token_type_ids,\n",
    "        }, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a98bab4-5b0e-499a-a211-02d8f984b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 지정\n",
    "tokenizer_pretrained = CHECKPOINT_NAME\n",
    "\n",
    "# train, test 데이터셋 생성\n",
    "train_data = TokenDataset(train, tokenizer_pretrained)\n",
    "test_data = TokenDataset(test, tokenizer_pretrained)\n",
    "\n",
    "# DataLoader로 이전에 생성한 Dataset를 지정하여, batch 구성, shuffle, num_workers 등을 설정합니다.\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f143725-2cd3-47bb-b2fb-203a55669693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
    "model_bert = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b9f080-708d-4cea-a9ee-06ad713de1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1개의 batch 꺼내기\n",
    "inputs, labels = next(iter(train_loader))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'gpu')\n",
    "\n",
    "# 데이터셋을 device 설정\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "inputs.keys()\n",
    "\n",
    "inputs['input_ids'].shape, inputs['attention_mask'].shape, inputs['token_type_ids'].shape\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(CHECKPOINT_NAME)\n",
    "config\n",
    "\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8bd1183-6151-4e95-b381-3bd26aa8a04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 768])\n",
      "tensor([[ 0.7084,  0.0178, -0.0605,  ...,  0.1665, -0.4782,  0.4814],\n",
      "        [ 0.4898, -0.2996,  1.0943,  ..., -0.0791, -0.1917,  0.5690],\n",
      "        [-1.3543,  0.2006, -2.3120,  ..., -0.8756, -0.7733, -0.2896],\n",
      "        ...,\n",
      "        [ 0.4732, -0.2664,  0.5495,  ..., -0.0539, -0.5493,  0.3092],\n",
      "        [ 0.5767,  0.1287, -0.1827,  ..., -0.1078, -1.1000,  0.3848],\n",
      "        [ 0.5198, -0.5776,  0.2068,  ...,  0.3438, -0.8761,  0.4701]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "torch.Size([8, 768])\n",
      "tensor([[-0.7681,  0.2148, -0.3681,  ..., -0.2496,  0.0010,  0.7050],\n",
      "        [-0.5588,  0.6010, -0.5276,  ...,  0.5221,  0.1940,  0.5238],\n",
      "        [ 0.3711,  0.2911, -0.9884,  ..., -0.9998,  0.7007, -0.2214],\n",
      "        ...,\n",
      "        [-0.9567,  0.3683, -0.7564,  ...,  0.0155, -0.0194,  0.8539],\n",
      "        [-0.8174,  0.1540, -0.8515,  ..., -0.2001,  0.0444,  0.8709],\n",
      "        [-0.7027,  0.2701, -0.8341,  ..., -0.8861,  0.0680,  0.6287]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "torch.Size([8, 2])\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inputs.keys()\n",
    "\n",
    "inputs['input_ids'].shape, inputs['attention_mask'].shape, inputs['token_type_ids'].shape\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(CHECKPOINT_NAME)\n",
    "config\n",
    "\n",
    "\n",
    "labels\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "# 모델 생성\n",
    "model_bert = BertModel.from_pretrained(CHECKPOINT_NAME).to(device)\n",
    "model_bert\n",
    "\n",
    "\n",
    "output = model_bert(**inputs)\n",
    "output.keys()\n",
    "output['last_hidden_state'].shape, output['pooler_output'].shape\n",
    "last_hidden_state = output['last_hidden_state']\n",
    "print(last_hidden_state.shape)\n",
    "print(last_hidden_state[:, 0, :])\n",
    "\n",
    "\n",
    "pooler_output = output['pooler_output']\n",
    "print(pooler_output.shape)\n",
    "print(pooler_output)\n",
    "\n",
    "fc = nn.Linear(768, 2)\n",
    "#fc = nn.Linear(868, 2)\n",
    "\n",
    "fc.to(device)\n",
    "fc_output = fc(last_hidden_state[:, 0, :])\n",
    "print(fc_output.shape)\n",
    "print(fc_output.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89ba822f-00d4-4302-942c-1714ebda7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertModel(nn.Module):\n",
    "    def __init__(self, bert_pretrained, dropout_rate=0.5):\n",
    "        # 부모클래스 초기화\n",
    "        super(CustomBertModel, self).__init__()\n",
    "        # 사전학습 모델 지정\n",
    "        self.bert = BertModel.from_pretrained(bert_pretrained)\n",
    "        # dropout 설정\n",
    "        self.dr = nn.Dropout(p=dropout_rate)\n",
    "        # 최종 출력층 정의\n",
    "        self.fc = nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # 입력을 pre-trained bert model 로 대입\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        # 결과의 last_hidden_state 가져옴\n",
    "        last_hidden_state = output['last_hidden_state']\n",
    "        # last_hidden_state[:, 0, :]는 [CLS] 토큰을 가져옴\n",
    "        x = self.dr(last_hidden_state[:, 0, :])\n",
    "        # FC 을 거쳐 최종 출력\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abbb78d1-df06-47c8-8b82-2e9a6841da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = CustomBertModel(CHECKPOINT_NAME)\n",
    "bert.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n",
    "optimizer = optim.Adam(bert.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3c51cd7-4e5a-405c-9803-42bab23c4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Progress Bar 출력\n",
    "\n",
    "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "    \n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    counts = 0\n",
    "    \n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n",
    "    \n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for idx, (inputs, labels) in enumerate(prograss_bar):\n",
    "        # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "        inputs = {k:v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = model(**inputs)\n",
    "        \n",
    "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.backward()\n",
    "        \n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "        # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "        _, pred = output.max(dim=1)\n",
    "        \n",
    "        # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "        # 합계는 corr 변수에 누적합니다.\n",
    "        corr += pred.eq(labels).sum().item()\n",
    "        counts += len(labels)\n",
    "        \n",
    "        # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "        # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        \n",
    "        # 프로그레스바에 학습 상황 업데이트\n",
    "        prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}, training accuracy: {corr / counts:.5f}\")\n",
    "        \n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "    \n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d391f96-1bf7-4456-9a80-70237a534822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    \n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "        \n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for inputs, labels in data_loader:\n",
    "            # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "            inputs = {k:v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(**inputs)\n",
    "            \n",
    "            # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "            _, pred = output.max(dim=1)\n",
    "            \n",
    "            # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "            # 합계는 corr 변수에 누적합니다.\n",
    "            corr += torch.sum(pred.eq(labels)).item()\n",
    "            \n",
    "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "            running_loss += loss_fn(output, labels).item() * labels.size(0)\n",
    "        \n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "        \n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ffe5ce94-0435-46b0-84a3-b01ecfc318e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02556, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from inf to 1.01721. Saving Model!\n",
      "epoch 01, loss: 0.00320, acc: 0.99900, val_loss: 1.01721, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04193, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02, loss: 0.00524, acc: 0.99800, val_loss: 1.06128, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03863, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03, loss: 0.00483, acc: 0.99800, val_loss: 1.09040, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01700, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04, loss: 0.00212, acc: 0.99900, val_loss: 1.11938, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02251, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05, loss: 0.00281, acc: 0.99900, val_loss: 1.09623, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01416, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 06, loss: 0.00177, acc: 0.99900, val_loss: 1.14486, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01123, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 07, loss: 0.00140, acc: 0.99900, val_loss: 1.18384, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03484, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 08, loss: 0.00435, acc: 0.99800, val_loss: 1.15406, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02856, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 09, loss: 0.00357, acc: 0.99800, val_loss: 1.14772, val_accuracy: 0.85200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03395, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 0.00424, acc: 0.99800, val_loss: 1.15213, val_accuracy: 0.85600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.00980, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss: 0.00123, acc: 0.99900, val_loss: 1.16283, val_accuracy: 0.85400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.17746, training accuracy: 0.99400: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss: 0.02218, acc: 0.99400, val_loss: 1.16601, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.50001, training accuracy: 0.98500: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 1.01721 to 0.81122. Saving Model!\n",
      "epoch 13, loss: 0.06250, acc: 0.98500, val_loss: 0.81122, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04672, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, loss: 0.00584, acc: 0.99800, val_loss: 0.93045, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.11283, training accuracy: 0.99500: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss: 0.01410, acc: 0.99500, val_loss: 1.01205, val_accuracy: 0.83400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04071, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, loss: 0.00509, acc: 0.99700, val_loss: 1.06358, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01586, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss: 0.00198, acc: 0.99900, val_loss: 1.07433, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01607, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss: 0.00201, acc: 0.99900, val_loss: 1.07298, val_accuracy: 0.84400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01220, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, loss: 0.00153, acc: 0.99900, val_loss: 1.10345, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.39081, training accuracy: 0.98500: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss: 0.04885, acc: 0.98500, val_loss: 0.82769, val_accuracy: 0.82800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.09983, training accuracy: 0.99500: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, loss: 0.01248, acc: 0.99500, val_loss: 0.92756, val_accuracy: 0.82400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.11105, training accuracy: 0.99600: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, loss: 0.01388, acc: 0.99600, val_loss: 0.81295, val_accuracy: 0.85800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02672, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, loss: 0.00334, acc: 0.99900, val_loss: 0.87742, val_accuracy: 0.85800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04843, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, loss: 0.00605, acc: 0.99700, val_loss: 0.96306, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03931, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, loss: 0.00491, acc: 0.99700, val_loss: 0.94337, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.22371, training accuracy: 0.98900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val_loss has been improved from 0.81122 to 0.78572. Saving Model!\n",
      "epoch 26, loss: 0.02796, acc: 0.98900, val_loss: 0.78572, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04044, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, loss: 0.00505, acc: 0.99800, val_loss: 0.91998, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.09744, training accuracy: 0.99600: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, loss: 0.01218, acc: 0.99600, val_loss: 0.89327, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02048, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, loss: 0.00256, acc: 0.99900, val_loss: 0.93903, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02180, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, loss: 0.00272, acc: 0.99800, val_loss: 0.96133, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01849, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, loss: 0.00231, acc: 0.99800, val_loss: 1.00186, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01673, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, loss: 0.00209, acc: 1.00000, val_loss: 1.18781, val_accuracy: 0.82200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03273, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, loss: 0.00409, acc: 0.99800, val_loss: 1.07288, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02693, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, loss: 0.00337, acc: 0.99800, val_loss: 1.08544, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01596, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, loss: 0.00199, acc: 0.99900, val_loss: 1.09038, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01829, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, loss: 0.00229, acc: 0.99800, val_loss: 1.10731, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02921, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, loss: 0.00365, acc: 0.99800, val_loss: 1.21208, val_accuracy: 0.82600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01375, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, loss: 0.00172, acc: 1.00000, val_loss: 1.28123, val_accuracy: 0.83000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01168, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, loss: 0.00146, acc: 0.99900, val_loss: 1.27839, val_accuracy: 0.83000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.00344, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, loss: 0.00043, acc: 1.00000, val_loss: 1.27112, val_accuracy: 0.83400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.14586, training accuracy: 0.99500: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, loss: 0.01823, acc: 0.99500, val_loss: 1.00778, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.05817, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, loss: 0.00727, acc: 0.99800, val_loss: 1.06452, val_accuracy: 0.83400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.10508, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, loss: 0.01313, acc: 0.99800, val_loss: 1.31362, val_accuracy: 0.81200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01862, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, loss: 0.00233, acc: 0.99900, val_loss: 1.16657, val_accuracy: 0.82000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02498, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, loss: 0.00312, acc: 0.99800, val_loss: 1.16209, val_accuracy: 0.82200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01742, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, loss: 0.00218, acc: 0.99900, val_loss: 1.18170, val_accuracy: 0.82400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01694, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, loss: 0.00212, acc: 0.99900, val_loss: 1.18512, val_accuracy: 0.83200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02141, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, loss: 0.00268, acc: 0.99800, val_loss: 1.17655, val_accuracy: 0.82800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01302, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, loss: 0.00163, acc: 0.99900, val_loss: 1.21617, val_accuracy: 0.82800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.16088, training accuracy: 0.99600: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss: 0.02011, acc: 0.99600, val_loss: 0.91679, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03590, training accuracy: 0.99700: 100%|█| 125/125 [00:15<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51, loss: 0.00449, acc: 0.99700, val_loss: 0.98638, val_accuracy: 0.84400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03522, training accuracy: 0.99600: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52, loss: 0.00440, acc: 0.99600, val_loss: 1.02659, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04309, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53, loss: 0.00539, acc: 0.99800, val_loss: 1.03634, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02456, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54, loss: 0.00307, acc: 0.99700, val_loss: 1.07603, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03472, training accuracy: 0.99700: 100%|█| 125/125 [00:15<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55, loss: 0.00434, acc: 0.99700, val_loss: 1.12192, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01881, training accuracy: 0.99900: 100%|█| 125/125 [00:15<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56, loss: 0.00235, acc: 0.99900, val_loss: 1.14714, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03885, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57, loss: 0.00486, acc: 0.99700, val_loss: 1.14538, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04193, training accuracy: 0.99600: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58, loss: 0.00524, acc: 0.99600, val_loss: 1.16140, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03084, training accuracy: 0.99700: 100%|█| 125/125 [00:15<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59, loss: 0.00386, acc: 0.99700, val_loss: 1.17063, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04904, training accuracy: 0.99600: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60, loss: 0.00613, acc: 0.99600, val_loss: 1.15897, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02545, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, loss: 0.00318, acc: 0.99700, val_loss: 1.16925, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03611, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62, loss: 0.00451, acc: 0.99800, val_loss: 1.16957, val_accuracy: 0.84400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02612, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 0.00327, acc: 0.99800, val_loss: 1.18935, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02442, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64, loss: 0.00305, acc: 0.99700, val_loss: 1.21051, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02679, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65, loss: 0.00335, acc: 0.99800, val_loss: 1.22096, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02197, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66, loss: 0.00275, acc: 0.99800, val_loss: 1.23370, val_accuracy: 0.84600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02589, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, loss: 0.00324, acc: 0.99800, val_loss: 1.25342, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03937, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68, loss: 0.00492, acc: 0.99700, val_loss: 1.25728, val_accuracy: 0.84200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02426, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69, loss: 0.00303, acc: 0.99800, val_loss: 1.26643, val_accuracy: 0.85200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03588, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70, loss: 0.00449, acc: 0.99700, val_loss: 1.28898, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01906, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71, loss: 0.00238, acc: 0.99800, val_loss: 1.32757, val_accuracy: 0.83800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01554, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72, loss: 0.00194, acc: 0.99900, val_loss: 1.29905, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.08453, training accuracy: 0.99600: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, loss: 0.01057, acc: 0.99600, val_loss: 1.19062, val_accuracy: 0.84400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.29407, training accuracy: 0.99100: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74, loss: 0.03676, acc: 0.99100, val_loss: 0.95780, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.11363, training accuracy: 0.99500: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75, loss: 0.01420, acc: 0.99500, val_loss: 0.95504, val_accuracy: 0.83200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.04641, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76, loss: 0.00580, acc: 0.99700, val_loss: 1.10141, val_accuracy: 0.83400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03037, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77, loss: 0.00380, acc: 0.99800, val_loss: 1.13397, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01479, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78, loss: 0.00185, acc: 0.99900, val_loss: 1.16315, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01491, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79, loss: 0.00186, acc: 0.99900, val_loss: 1.20325, val_accuracy: 0.84400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02705, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, loss: 0.00338, acc: 0.99900, val_loss: 1.34656, val_accuracy: 0.83000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.18827, training accuracy: 0.99500: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81, loss: 0.02353, acc: 0.99500, val_loss: 0.99318, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02807, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82, loss: 0.00351, acc: 0.99900, val_loss: 1.07516, val_accuracy: 0.83200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.13585, training accuracy: 0.99600: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83, loss: 0.01698, acc: 0.99600, val_loss: 0.93828, val_accuracy: 0.83000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.09596, training accuracy: 0.99500: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84, loss: 0.01199, acc: 0.99500, val_loss: 0.87515, val_accuracy: 0.83200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01707, training accuracy: 0.99900: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85, loss: 0.00213, acc: 0.99900, val_loss: 0.97693, val_accuracy: 0.83400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.03132, training accuracy: 0.99700: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86, loss: 0.00392, acc: 0.99700, val_loss: 0.96728, val_accuracy: 0.83400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02087, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87, loss: 0.00261, acc: 0.99800, val_loss: 0.97802, val_accuracy: 0.84000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01169, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88, loss: 0.00146, acc: 1.00000, val_loss: 1.01386, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.00735, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89, loss: 0.00092, acc: 1.00000, val_loss: 1.03141, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.00560, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90, loss: 0.00070, acc: 1.00000, val_loss: 1.07107, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02432, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91, loss: 0.00304, acc: 0.99800, val_loss: 1.07792, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01888, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92, loss: 0.00236, acc: 0.99800, val_loss: 1.07689, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.00794, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93, loss: 0.00099, acc: 1.00000, val_loss: 1.10005, val_accuracy: 0.84800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01249, training accuracy: 0.99900: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94, loss: 0.00156, acc: 0.99900, val_loss: 1.10765, val_accuracy: 0.85200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.01593, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95, loss: 0.00199, acc: 0.99800, val_loss: 1.11802, val_accuracy: 0.85200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02182, training accuracy: 0.99800: 100%|█| 125/125 [00:14<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96, loss: 0.00273, acc: 0.99800, val_loss: 1.12068, val_accuracy: 0.85200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02464, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97, loss: 0.00308, acc: 0.99800, val_loss: 1.12433, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.00782, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98, loss: 0.00098, acc: 1.00000, val_loss: 1.13372, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.00924, training accuracy: 1.00000: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99, loss: 0.00115, acc: 1.00000, val_loss: 1.14089, val_accuracy: 0.85000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loss: 0.02694, training accuracy: 0.99800: 100%|█| 125/125 [00:13<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, loss: 0.00337, acc: 0.99800, val_loss: 1.14634, val_accuracy: 0.84800\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# checkpoint로 저장할 모델의 이름을 정의 합니다.\n",
    "model_name = 'bert-kor-base'\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "# Epoch 별 훈련 및 검증을 수행합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    # Model Training\n",
    "    # 훈련 손실과 정확도를 반환 받습니다.\n",
    "    train_loss, train_acc = model_train(bert, train_loader, loss_fn, optimizer, device)\n",
    "\n",
    "    # 검증 손실과 검증 정확도를 반환 받습니다.\n",
    "    val_loss, val_acc = model_evaluate(bert, test_loader, loss_fn, device)   \n",
    "    \n",
    "    # val_loss 가 개선되었다면 min_loss를 갱신하고 model의 가중치(weights)를 저장합니다.\n",
    "    if val_loss < min_loss:\n",
    "        print(f'[INFO] val_loss has been improved from {min_loss:.5f} to {val_loss:.5f}. Saving Model!')\n",
    "        min_loss = val_loss\n",
    "        torch.save(bert.state_dict(), f'{model_name}.pth')\n",
    "    \n",
    "    # Epoch 별 결과를 출력합니다.\n",
    "    print(f'epoch {epoch+1:02d}, loss: {train_loss:.5f}, acc: {train_acc:.5f}, val_loss: {val_loss:.5f}, val_accuracy: {val_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e8086ff-86bd-470d-95ea-b5167e024ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.load_state_dict(torch.load(f'{model_name}.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8419ce4-b9c5-41d2-abf0-41f26c2e04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPredictor():\n",
    "    def __init__(self, model, tokenizer, labels: dict):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = labels\n",
    "        \n",
    "    def predict(self, sentence):\n",
    "        # 토큰화 처리\n",
    "        tokens = self.tokenizer(\n",
    "            sentence,                # 1개 문장 \n",
    "            return_tensors='pt',     # 텐서로 반환\n",
    "            truncation=True,         # 잘라내기 적용\n",
    "            padding='max_length',    # 패딩 적용\n",
    "            add_special_tokens=True  # 스페셜 토큰 적용\n",
    "        )\n",
    "        tokens.to(device)\n",
    "        prediction = self.model(**tokens)\n",
    "        prediction = F.softmax(prediction, dim=1)\n",
    "        output = prediction.argmax(dim=1).item()\n",
    "        prob, result = prediction.max(dim=1)[0].item(), self.labels[output]\n",
    "        print(f'[{result}]\\n확률은: {prob*100:.3f}% 입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac530083-473a-4731-b73a-a7d9eeec99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(CHECKPOINT_NAME)\n",
    "\n",
    "labels = {\n",
    "    0: '부정 리뷰 입니다.', \n",
    "    1: '긍정 리뷰 입니다.'\n",
    "}\n",
    "\n",
    "# CustomPredictor 인스턴스를 생성합니다.\n",
    "predictor = CustomPredictor(bert, tokenizer, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc6008ad-e8e4-49bd-9695-39fe31b6b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(predictor):\n",
    "    input_sentence = input('문장을 입력해 주세요: ')\n",
    "    predictor.predict(input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a81dbf0-8a8f-4195-9b64-27c164766689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "문장을 입력해 주세요:  이런 걸 왜 보는 거야?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[부정 리뷰 입니다.]\n",
      "확률은: 99.978% 입니다.\n"
     ]
    }
   ],
   "source": [
    "predict_sentence(predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116202a-cbd8-4743-a4bf-36d46ae602b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49da3c1-8bba-4770-8b1b-b2a4f614a6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad0950-c1eb-46fe-a7ed-c5472df93631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38b62e-87a2-49fc-aea0-8d8fc84930a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082764d0-ee4b-4741-b033-dd15a6b2a3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf97c3-1ad1-4b11-a92a-9428c95483d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e95b308-e63e-4018-add2-9a5d224d91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: cuda:1\n",
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/eternal/Korpora/nsmc/ratings_train.txt\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/eternal/Korpora/nsmc/ratings_test.txt\n",
      "torch.Size([8, 512, 768])\n",
      "tensor([[-0.8334, -0.4274,  0.7557,  ...,  0.1635, -1.6913,  0.4360],\n",
      "        [ 0.0560, -0.0387,  0.4207,  ...,  0.1862, -0.2313,  0.2286],\n",
      "        [ 0.6696,  0.1019,  0.0411,  ...,  0.1238, -0.9931,  0.4644],\n",
      "        ...,\n",
      "        [ 0.3768,  0.3190,  0.1374,  ...,  0.7546, -0.0964,  0.9854],\n",
      "        [-1.4014,  0.6145,  0.3306,  ..., -0.1831, -2.3801, -0.0272],\n",
      "        [ 1.0798,  0.0325,  0.2345,  ...,  0.4324, -0.9258,  0.3030]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "torch.Size([8, 768])\n",
      "tensor([[ 0.4874,  0.0962, -0.9998,  ...,  0.1649,  0.6896, -0.3976],\n",
      "        [ 0.9119, -0.1465, -1.0000,  ...,  0.3177,  0.7596,  0.4693],\n",
      "        [-0.7957,  0.2134, -0.7786,  ..., -0.4489,  0.2137,  0.8102],\n",
      "        ...,\n",
      "        [-0.8243,  0.4706, -0.7330,  ...,  0.8809,  0.1489,  0.7493],\n",
      "        [-0.0916,  0.1057, -0.9999,  ...,  0.4224,  0.0732, -0.9499],\n",
      "        [-0.9461,  0.1907, -0.9154,  ..., -0.0866,  0.5002,  0.9574]],\n",
      "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
      "torch.Size([8, 2])\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "문장을 입력해 주세요:  ㅈ같다\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[부정 리뷰 입니다.]\n",
      "확률은: 99.997% 입니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 한글 자연어 처리 데이터셋\n",
    "from Korpora import Korpora\n",
    "\n",
    "# 토크나이저 관련 경고 무시하기 위하여 설정\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = 'true'\n",
    "\n",
    "# device 지정\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'사용 디바이스: {device}')\n",
    "\n",
    "corpus = Korpora.load(\"nsmc\")\n",
    "\n",
    "train['length'] = train['document'].apply(lambda x: len(str(x)))\n",
    "test['length'] = test['document'].apply(lambda x: len(str(x)))\n",
    "CHECKPOINT_NAME = 'kykim/bert-kor-base'\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TokenDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, dataframe, tokenizer_pretrained):\n",
    "        # sentence, label 컬럼으로 구성된 데이터프레임 전달\n",
    "        self.data = dataframe        \n",
    "        # Huggingface 토크나이저 생성\n",
    "        self.tokenizer = BertTokenizerFast.from_pretrained(tokenizer_pretrained)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data.iloc[idx]['document']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        # 토큰화 처리\n",
    "        tokens = self.tokenizer(\n",
    "            sentence,                # 1개 문장 \n",
    "            return_tensors='pt',     # 텐서로 반환\n",
    "            truncation=True,         # 잘라내기 적용\n",
    "            padding='max_length',    # 패딩 적용\n",
    "            add_special_tokens=True  # 스페셜 토큰 적용\n",
    "        )\n",
    "\n",
    "        input_ids = tokens['input_ids'].squeeze(0)           # 2D -> 1D\n",
    "        attention_mask = tokens['attention_mask'].squeeze(0) # 2D -> 1D\n",
    "        token_type_ids = torch.zeros_like(attention_mask)\n",
    "\n",
    "        # input_ids, attention_mask, token_type_ids 이렇게 3가지 요소를 반환하도록 합니다.\n",
    "        # input_ids: 토큰\n",
    "        # attention_mask: 실제 단어가 존재하면 1, 패딩이면 0 (패딩은 0이 아닐 수 있습니다)\n",
    "        # token_type_ids: 문장을 구분하는 id. 단일 문장인 경우에는 전부 0\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask, \n",
    "            'token_type_ids': token_type_ids,\n",
    "        }, torch.tensor(label)\n",
    "\n",
    "# 토크나이저 지정\n",
    "tokenizer_pretrained = CHECKPOINT_NAME\n",
    "\n",
    "# train, test 데이터셋 생성\n",
    "train_data = TokenDataset(train, tokenizer_pretrained)\n",
    "test_data = TokenDataset(test, tokenizer_pretrained)\n",
    "\n",
    "# DataLoader로 이전에 생성한 Dataset를 지정하여, batch 구성, shuffle, num_workers 등을 설정합니다.\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True, num_workers=8)\n",
    "\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "tokenizer_bert = BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
    "model_bert = BertModel.from_pretrained(\"kykim/bert-kor-base\")\n",
    "\n",
    "# 1개의 batch 꺼내기\n",
    "inputs, labels = next(iter(train_loader))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'gpu')\n",
    "\n",
    "# 데이터셋을 device 설정\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "inputs.keys()\n",
    "\n",
    "inputs['input_ids'].shape, inputs['attention_mask'].shape, inputs['token_type_ids'].shape\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(CHECKPOINT_NAME)\n",
    "config\n",
    "\n",
    "\n",
    "labels\n",
    "inputs.keys()\n",
    "\n",
    "inputs['input_ids'].shape, inputs['attention_mask'].shape, inputs['token_type_ids'].shape\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(CHECKPOINT_NAME)\n",
    "config\n",
    "\n",
    "\n",
    "labels\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "# 모델 생성\n",
    "model_bert = BertModel.from_pretrained(CHECKPOINT_NAME).to(device)\n",
    "model_bert\n",
    "\n",
    "\n",
    "output = model_bert(**inputs)\n",
    "output.keys()\n",
    "output['last_hidden_state'].shape, output['pooler_output'].shape\n",
    "last_hidden_state = output['last_hidden_state']\n",
    "print(last_hidden_state.shape)\n",
    "print(last_hidden_state[:, 0, :])\n",
    "\n",
    "\n",
    "pooler_output = output['pooler_output']\n",
    "print(pooler_output.shape)\n",
    "print(pooler_output)\n",
    "\n",
    "fc = nn.Linear(768, 2)\n",
    "#fc = nn.Linear(868, 2)\n",
    "\n",
    "fc.to(device)\n",
    "fc_output = fc(last_hidden_state[:, 0, :])\n",
    "print(fc_output.shape)\n",
    "print(fc_output.argmax(dim=1))\n",
    "\n",
    "class CustomBertModel(nn.Module):\n",
    "    def __init__(self, bert_pretrained, dropout_rate=0.5):\n",
    "        # 부모클래스 초기화\n",
    "        super(CustomBertModel, self).__init__()\n",
    "        # 사전학습 모델 지정\n",
    "        self.bert = BertModel.from_pretrained(bert_pretrained)\n",
    "        # dropout 설정\n",
    "        self.dr = nn.Dropout(p=dropout_rate)\n",
    "        # 최종 출력층 정의\n",
    "        self.fc = nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # 입력을 pre-trained bert model 로 대입\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        # 결과의 last_hidden_state 가져옴\n",
    "        last_hidden_state = output['last_hidden_state']\n",
    "        # last_hidden_state[:, 0, :]는 [CLS] 토큰을 가져옴\n",
    "        x = self.dr(last_hidden_state[:, 0, :])\n",
    "        # FC 을 거쳐 최종 출력\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "bert = CustomBertModel(CHECKPOINT_NAME)\n",
    "bert.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 정의: bert.paramters()와 learning_rate 설정\n",
    "optimizer = optim.Adam(bert.parameters(), lr=1e-5)\n",
    "\n",
    "from tqdm import tqdm  # Progress Bar 출력\n",
    "\n",
    "def model_train(model, data_loader, loss_fn, optimizer, device):\n",
    "    # 모델을 훈련모드로 설정합니다. training mode 일 때 Gradient 가 업데이트 됩니다. 반드시 train()으로 모드 변경을 해야 합니다.\n",
    "    model.train()\n",
    "    \n",
    "    # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    counts = 0\n",
    "    \n",
    "    # 예쁘게 Progress Bar를 출력하면서 훈련 상태를 모니터링 하기 위하여 tqdm으로 래핑합니다.\n",
    "    prograss_bar = tqdm(data_loader, unit='batch', total=len(data_loader), mininterval=1)\n",
    "    \n",
    "    # mini-batch 학습을 시작합니다.\n",
    "    for idx, (inputs, labels) in enumerate(prograss_bar):\n",
    "        # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "        inputs = {k:v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 누적 Gradient를 초기화 합니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Propagation을 진행하여 결과를 얻습니다.\n",
    "        output = model(**inputs)\n",
    "        \n",
    "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        # 오차역전파(Back Propagation)을 진행하여 미분 값을 계산합니다.\n",
    "        loss.backward()\n",
    "        \n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n",
    "        \n",
    "        # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "        # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "        _, pred = output.max(dim=1)\n",
    "        \n",
    "        # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "        # 합계는 corr 변수에 누적합니다.\n",
    "        corr += pred.eq(labels).sum().item()\n",
    "        counts += len(labels)\n",
    "        \n",
    "        # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "        # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "        # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        \n",
    "        # 프로그레스바에 학습 상황 업데이트\n",
    "        prograss_bar.set_description(f\"training loss: {running_loss/(idx+1):.5f}, training accuracy: {corr / counts:.5f}\")\n",
    "        \n",
    "    # 누적된 정답수를 전체 개수로 나누어 주면 정확도가 산출됩니다.\n",
    "    acc = corr / len(data_loader.dataset)\n",
    "    \n",
    "    # 평균 손실(loss)과 정확도를 반환합니다.\n",
    "    # train_loss, train_acc\n",
    "    return running_loss / len(data_loader.dataset), acc\n",
    "\n",
    "def model_evaluate(model, data_loader, loss_fn, device):\n",
    "    # model.eval()은 모델을 평가모드로 설정을 바꾸어 줍니다. \n",
    "    # dropout과 같은 layer의 역할 변경을 위하여 evaluation 진행시 꼭 필요한 절차 입니다.\n",
    "    model.eval()\n",
    "    \n",
    "    # Gradient가 업데이트 되는 것을 방지 하기 위하여 반드시 필요합니다.\n",
    "    with torch.no_grad():\n",
    "        # loss와 accuracy 계산을 위한 임시 변수 입니다. 0으로 초기화합니다.\n",
    "        corr = 0\n",
    "        running_loss = 0\n",
    "        \n",
    "        # 배치별 evaluation을 진행합니다.\n",
    "        for inputs, labels in data_loader:\n",
    "            # inputs, label 데이터를 device 에 올립니다. (cuda:0 혹은 cpu)\n",
    "            inputs = {k:v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 모델에 Forward Propagation을 하여 결과를 도출합니다.\n",
    "            output = model(**inputs)\n",
    "            \n",
    "            # output의 max(dim=1)은 max probability와 max index를 반환합니다.\n",
    "            # max probability는 무시하고, max index는 pred에 저장하여 label 값과 대조하여 정확도를 도출합니다.\n",
    "            _, pred = output.max(dim=1)\n",
    "            \n",
    "            # pred.eq(lbl).sum() 은 정확히 맞춘 label의 합계를 계산합니다. item()은 tensor에서 값을 추출합니다.\n",
    "            # 합계는 corr 변수에 누적합니다.\n",
    "            corr += torch.sum(pred.eq(labels)).item()\n",
    "            \n",
    "            # loss 값은 1개 배치의 평균 손실(loss) 입니다. img.size(0)은 배치사이즈(batch size) 입니다.\n",
    "            # loss 와 img.size(0)를 곱하면 1개 배치의 전체 loss가 계산됩니다.\n",
    "            # 이를 누적한 뒤 Epoch 종료시 전체 데이터셋의 개수로 나누어 평균 loss를 산출합니다.\n",
    "            running_loss += loss_fn(output, labels).item() * labels.size(0)\n",
    "        \n",
    "        # validation 정확도를 계산합니다.\n",
    "        # 누적한 정답숫자를 전체 데이터셋의 숫자로 나누어 최종 accuracy를 산출합니다.\n",
    "        acc = corr / len(data_loader.dataset)\n",
    "        \n",
    "        # 결과를 반환합니다.\n",
    "        # val_loss, val_acc\n",
    "        return running_loss / len(data_loader.dataset), acc\n",
    "\n",
    "bert.load_state_dict(torch.load(f'{model_name}.pth'))\n",
    "tokenizer = BertTokenizerFast.from_pretrained(CHECKPOINT_NAME)\n",
    "\n",
    "labels = {\n",
    "    0: '부정 리뷰 입니다.', \n",
    "    1: '긍정 리뷰 입니다.'\n",
    "}\n",
    "\n",
    "# CustomPredictor 인스턴스를 생성합니다.\n",
    "predictor = CustomPredictor(bert, tokenizer, labels)\n",
    "\n",
    "def predict_sentence(predictor):\n",
    "    input_sentence = input('문장을 입력해 주세요: ')\n",
    "    predictor.predict(input_sentence)\n",
    "\n",
    "predict_sentence(predictor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36f117-3592-4353-9a11-edb7046557ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b44b4-50c6-41ec-8813-f666f401bc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
